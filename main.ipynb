{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scratchai.preproccessing import split_data, StandardScaler\n",
    "from scratchai.linear_models import LogisticRegression\n",
    "from scratchai.cart import DecisionTreeClassifier\n",
    "from scratchai.plotting import plot_generalization_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a dataframe\n",
    "loan_data_raw = pd.read_csv(\"data\\Bank_Personal_Loan_Modelling.csv\")\n",
    "loan_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include only the columns that may be useful\n",
    "columns = ['Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Education', 'Mortgage', 'Securities Account', 'CD Account', 'Personal Loan']\n",
    "loan_data = loan_data_raw[columns]\n",
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "missing_vals = loan_data.isna().sum()\n",
    "dupl_rows = loan_data.duplicated().sum()\n",
    "\n",
    "print(\n",
    "    f\"Count of Missing values:\\n {missing_vals} \\n\",\n",
    "    f\"Number of duplicate rows: {dupl_rows}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = loan_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic visualisation\n",
    "loan_data.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of custumers who accepted the personal loan: {loan_data.loc[loan_data['Personal Loan'] == 1,:].shape[0]}\\n\",\n",
    "    f\"Number of custumers who didn't: {loan_data.loc[loan_data['Personal Loan'] == 0].shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some graphs\n",
    "for column in ['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']:\n",
    "    plt.hist(loan_data[column])\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Family', 'Education', 'Securities Account', 'CD Account']:\n",
    "    plt.hist(loan_data[column])\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert some variables into bins to explore if there is any patterns\n",
    "loan_data.loc[:, 'Age_group'] = pd.cut(loan_data['Age'], bins = [20, 40, 50, 60, 80], labels = ['20-40', '40-50','50-60','60-80']).astype('O')\n",
    "loan_data.loc[:, 'Income_group'] = pd.cut(loan_data['Income'], bins = [5, 50, 100, 300], labels = ['low', 'medium', 'high']).astype('O')\n",
    "\n",
    "for column in ['Age_group', 'Income_group']:\n",
    "    plt.hist(loan_data[column])\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Age', 'Experience', 'Income', 'CCAvg', 'Education', 'Mortgage', 'Personal Loan']\n",
    "sns.pairplot(loan_data[columns], hue = 'Personal Loan', corner = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cliping outliers in the data\n",
    "loan_data['Income'] = loan_data['Income'].clip(lower = 0, upper = 150)\n",
    "loan_data['CCAvg'] = loan_data['CCAvg'].clip(lower = 0, upper = 5)\n",
    "loan_data['Mortgage'] = loan_data['Mortgage'].clip(lower = 0, upper = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = ['Age_group','Experience', 'Income', 'Family', 'CCAvg', 'Education', 'Mortgage']\n",
    "label = 'Personal Loan'\n",
    "\n",
    "processed_data = loan_data[input_features + [label]]\n",
    "\n",
    "processed_data = processed_data.join(pd.get_dummies(processed_data['Age_group']).astype('int'))\n",
    "processed_data = processed_data.drop('Age_group', axis = 1)\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaled_columns = ['Experience', 'Income', 'Family', 'CCAvg', 'Education', 'Mortgage']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "processed_data = scaler.transform(processed_data, columns = scaled_columns)\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "processed_data = processed_data.sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "train_data, testing_data = split_data(processed_data, split_size = 0.7)\n",
    "logistic_regressor_test_data, valid_data = split_data(testing_data, split_size = 0.5)\n",
    "\n",
    "X_train, y_train = train_data.drop(label, axis = 1).values, train_data[label].values\n",
    "X_valid, y_valid = valid_data.drop(label, axis = 1).values, valid_data[label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and fit a logisitic regression model to the data\n",
    "\n",
    "logistic_regressor = LogisticRegression()\n",
    "logistic_regressor.fit(X_train, y_train, learning_rate = 0.01, batch_size = 2048, epochs = 750, reg_rate = 0.5, X_valid = X_valid, y_valid=  y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the generalization curve to make sure that the model didn't overfit the data\n",
    "plot_generalization_curve(logistic_regressor.training_losses, logistic_regressor.validation_losses, logistic_regressor.traning_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratchai.metrics import accuracy, precision, recall\n",
    "\n",
    "def evaluate_model(y_true, y_pred,*, model_name = ''):\n",
    "    for metric, func in [('Accuracy', accuracy),('Precision', precision),('Recall', recall)]:\n",
    "        print(f\"{model_name} {metric}: {func(y_true, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the logistic regression model on validation data\n",
    "logistic_regressor.threshold = .5\n",
    "y_pred = logistic_regressor.classifie(X_valid)\n",
    "\n",
    "evaluate_model(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for the decision tree\n",
    "loan_data = loan_data[input_features + [label]]\n",
    "\n",
    "# split the data\n",
    "train_data, testing_data = split_data(loan_data, split_size = 0.7)\n",
    "tree_classifier_test_data, valid_data = split_data(testing_data, split_size = 0.5)\n",
    "\n",
    "X_train, y_train = train_data[input_features].values, train_data[label].values\n",
    "X_valid, y_valid = valid_data[input_features].values, valid_data[label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit a Descision tree to the data\n",
    "tree_calssifier = DecisionTreeClassifier(max_depth = 15, min_samples_split = 10)\n",
    "tree_calssifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the decision tree on validation data\n",
    "y_pred = tree_calssifier.predict(X_valid)\n",
    "\n",
    "evaluate_model(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaludate both models on testing data\n",
    "X_test, y_test = logistic_regressor_test_data.drop(label, axis = 1).values, logistic_regressor_test_data[label]\n",
    "y_pred = logistic_regressor.classifie(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred, model_name = 'Logistic Regressor')\n",
    "\n",
    "X_test, y_test = tree_classifier_test_data[input_features].values, tree_classifier_test_data[label].values\n",
    "y_pred = tree_calssifier.predict(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred, model_name = 'Decision tree classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
